# Розділ 43: Rayon — Паралелізм даних

---

## 📋 Анотація

У попередніх розділах ви опанували **async/await** та **Tokio** для роботи з I/O-bound задачами: мережеві запити, очікування на каналах, таймери. Async чудово працює, коли програма **чекає** — чекає відповіді від сервера, чекає даних від сенсора, чекає повідомлення від іншого актора. Але що робити, коли програма не чекає, а **рахує**?

Обчислення оптимального шляху для дрона — це не очікування, це математика. Обробка зображення з камери — це не мережа, це пікселі та алгоритми. Розрахунок траєкторій для всього рою — це мільйони операцій над числами. Тут async не допомагає: поки CPU виконує обчислення, він зайнятий на 100%, і немає чого "поступатись".

**Rayon** — бібліотека для **паралелізму даних** (data parallelism). Вона дозволяє легко розподілити обчислення на всі ядра процесора. Ключова ідея проста: замість `iter()` пишемо `par_iter()` — і Rayon автоматично розділяє дані між потоками, виконує обчислення паралельно, збирає результати. Код майже не змінюється, але виконується в N разів швидше (де N — кількість ядер).

Цей розділ пояснює фундаментальну різницю між паралелізмом задач (Tokio) та паралелізмом даних (Rayon), навчить вас обирати правильний інструмент, і покаже, як поєднувати обидва підходи в одній системі.

---

## 🎯 Цілі навчання

Після завершення цього розділу ви зможете:

1. **Пояснити** різницю між паралелізмом задач та паралелізмом даних
2. **Застосовувати** Rayon для паралельної обробки колекцій
3. **Обирати** правильний інструмент: Tokio чи Rayon
4. **Оцінювати** коли паралелізм вигідний, а коли — ні
5. **Поєднувати** async код з паралельними обчисленнями через spawn_blocking
6. **Оптимізувати** CPU-bound операції в рої агентів

---

## 📚 Ключові терміни

| Термін | Визначення |
|--------|------------|
| **Паралелізм даних** | Одна операція застосовується паралельно до багатьох елементів даних |
| **Паралелізм задач** | Різні задачі виконуються одночасно, кожна зі своєю логікою |
| **Work Stealing** | Алгоритм балансування навантаження: вільні потоки "крадуть" роботу в зайнятих |
| **par_iter** | Паралельний ітератор Rayon; заміна для iter() |
| **Thread Pool** | Пул заздалегідь створених потоків для виконання паралельних задач |
| **CPU-bound** | Задача, що обмежена швидкістю процесора (обчислення) |
| **I/O-bound** | Задача, що обмежена швидкістю вводу-виводу (мережа, диск) |

---

## 💡 Мотиваційний кейс: Планування маршрутів для рою

Уявімо рій з 100 БПЛА. Кожен агент має обчислити оптимальний маршрут до цілі — це алгоритм A* або подібний, що займає приблизно 10 мілісекунд на одне обчислення.

**Послідовний підхід:**
```rust
Агент 1: [==========] 10мс
Агент 2:             [==========] 10мс
Агент 3:                          [==========] 10мс
...
Агент 100:                                              [==========] 10мс
──────────────────────────────────────────────────────────────────────────►
                                                                   1 секунда
```

100 агентів × 10мс = **1 секунда**. Для системи реального часу — неприйнятно.

**Паралельний підхід (8 ядер):**
```text
Ядро 1: [Agent 1][Agent 9][Agent 17]...
Ядро 2: [Agent 2][Agent 10][Agent 18]...
Ядро 3: [Agent 3][Agent 11][Agent 19]...
Ядро 4: [Agent 4][Agent 12][Agent 20]...
Ядро 5: [Agent 5][Agent 13][Agent 21]...
Ядро 6: [Agent 6][Agent 14][Agent 22]...
Ядро 7: [Agent 7][Agent 15][Agent 23]...
Ядро 8: [Agent 8][Agent 16][Agent 24]...
────────────────────────────────────────►
                             ~125мс
```

100 агентів / 8 ядер ≈ 13 обчислень на ядро × 10мс ≈ **130 мілісекунд**. Прискорення майже в 8 разів!

Async тут не допоможе — немає очікування, тільки чисті обчислення. Потрібен справжній паралелізм на рівні CPU ядер. Саме для цього існує Rayon.

---

## 43.1 ПАРАЛЕЛІЗМ ЗАДАЧ VS ПАРАЛЕЛІЗМ ДАНИХ

### 43.1.1 Два фундаментально різних підходи

Перш ніж вивчати Rayon, важливо зрозуміти фундаментальну різницю між двома видами паралелізму. Це різні концепції, що вимагають різних інструментів.

**Паралелізм задач (Task Parallelism)**

Різні задачі виконуються одночасно. Кожна задача має свою власну логіку, можливо зовсім іншу. Задачі можуть бути незалежними або координуватись через повідомлення.

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ПАРАЛЕЛІЗМ ЗАДАЧ                                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Час ──────────────────────────────────────────────────────────────►│
│                                                                     │
│  Задача A: [Завантаж файл]────────────────────►[Обробка]           │
│                                                                     │
│  Задача B: [HTTP запит]─────►[Чекаємо відповідь]────►[Парсинг]     │
│                                                                     │
│  Задача C: [Читаємо сенсор]──►[Фільтр]──►[Надсилаємо]             │
│                                                                     │
│  Кожна задача — своя логіка, свій потік виконання                  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

Приклади: веб-сервер обробляє багато з'єднань, кожне зі своєю логікою; актори обробляють повідомлення незалежно; агенти виконують різні місії.

**Інструменти**: Tokio, async/await, threads, actors.

**Паралелізм даних (Data Parallelism)**

Одна і та сама операція застосовується до багатьох елементів даних одночасно. Всі елементи обробляються однаковою логікою, просто паралельно.

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ПАРАЛЕЛІЗМ ДАНИХ                                  │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Вхід: [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12]         │
│         │   │   │   │   │   │   │   │   │    │    │    │          │
│         ▼   ▼   ▼   ▼   ▼   ▼   ▼   ▼   ▼    ▼    ▼    ▼          │
│        ┌───────────────────────────────────────────────────┐       │
│        │          ОДНА ОПЕРАЦІЯ: x → x²                    │       │
│        │      (виконується на всіх ядрах паралельно)       │       │
│        └───────────────────────────────────────────────────┘       │
│         │   │   │   │   │   │   │   │   │    │    │    │          │
│         ▼   ▼   ▼   ▼   ▼   ▼   ▼   ▼   ▼    ▼    ▼    ▼          │
│  Вихід:[1] [4] [9] [16][25][36][49][64][81][100][121][144]        │
│                                                                     │
│  Та сама операція — багато даних                                   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

Приклади: обчислити квадрат кожного числа в масиві; знайти всі прості числа; обробити кожен піксель зображення; розрахувати шлях для кожного агента.

**Інструменти**: Rayon, SIMD, GPU computing.

### 43.1.2 Порівняльна таблиця

| Характеристика | Паралелізм задач | Паралелізм даних |
|----------------|------------------|------------------|
| **Що паралельне** | Різні задачі | Одна операція на різних даних |
| **Логіка** | Кожна задача — своя | Однакова для всіх |
| **Типовий випадок** | I/O-bound операції | CPU-bound обчислення |
| **Комунікація** | Через канали/повідомлення | Мінімальна або відсутня |
| **Інструменти в Rust** | Tokio, threads | Rayon, SIMD |
| **Приклад** | Веб-сервер з з'єднаннями | Обробка масиву чисел |

### 43.1.3 Коли що використовувати: правило великого пальця

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ДЕРЕВО РІШЕНЬ                                     │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│                    Яка природа задачі?                              │
│                           │                                         │
│              ┌────────────┴────────────┐                           │
│              ▼                         ▼                           │
│       Чекаємо на щось?          Рахуємо без зупинки?               │
│       (мережа, диск,            (математика, алгоритми,            │
│        таймери, канали)          обробка даних)                    │
│              │                         │                           │
│              ▼                         ▼                           │
│         ┌─────────┐              ┌─────────┐                       │
│         │  TOKIO  │              │  RAYON  │                       │
│         │ async   │              │par_iter │                       │
│         └─────────┘              └─────────┘                       │
│                                                                     │
│  Додаткове питання для Rayon:                                      │
│  Чи є багато ОДНАКОВИХ операцій над різними даними?                │
│  Так → Rayon ідеально підходить                                    │
│  Ні (різні операції) → можливо, threads краще                      │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Практичні приклади:**

| Задача | Характер | Інструмент |
|--------|----------|------------|
| HTTP запити до API | I/O-bound, очікування | Tokio |
| Читання з бази даних | I/O-bound, очікування | Tokio |
| Обчислення хешів для файлів | CPU-bound, однакова операція | Rayon |
| Обробка зображень | CPU-bound, однакова операція | Rayon |
| Веб-сервер | I/O-bound, різні запити | Tokio |
| Пошук у великому масиві | CPU-bound, однакова операція | Rayon |
| Актори обробляють повідомлення | I/O-bound, різна логіка | Tokio |
| Розрахунок шляхів для рою | CPU-bound, однакова операція | Rayon |

---

## 43.2 ОСНОВИ RAYON

### 43.2.1 Налаштування проєкту

Rayon додається як звичайна залежність у Cargo.toml:

```toml
[dependencies]
rayon = "1.10"
```

Rayon автоматично створює **глобальний пул потоків** при першому використанні. За замовчуванням створюється стільки потоків, скільки логічних ядер CPU. Для 8-ядерного процесора — 8 потоків.

Це означає, що вам не потрібно нічого конфігурувати для початку роботи — Rayon "просто працює".

### 43.2.2 Паралельні ітератори: ключова абстракція

Основна абстракція Rayon — **паралельні ітератори**. Вони мають API, майже ідентичний звичайним ітераторам, але виконуються паралельно на всіх ядрах.

Ось як виглядає перехід від послідовного до паралельного коду:

```rust
use rayon::prelude::*;

// Послідовний ітератор — виконується в одному потоці
let sum_sequential: i64 = (0..1_000_000)
    .into_iter()
    .map(|x| x * x)
    .sum();

// Паралельний ітератор — виконується на всіх ядрах
let sum_parallel: i64 = (0..1_000_000)
    .into_par_iter()    // <-- Єдина зміна!
    .map(|x| x * x)
    .sum();
```

Різниця лише в одному методі: `into_iter()` → `into_par_iter()`. Решта коду — `map()`, `sum()` — **абсолютно ідентична**. Але перший варіант використовує одне ядро, а другий — усі доступні.

### 43.2.3 Що відбувається всередині

Коли ви викликаєте `into_par_iter()`, Rayon:

1. **Розділяє** дані на частини (chunks)
2. **Розподіляє** частини між потоками з пулу
3. **Виконує** операції паралельно
4. **Збирає** результати в правильному порядку

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    RAYON ВНУТРІШНЯ МЕХАНІКА                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Вхідні дані: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]             │
│                                                                     │
│  Крок 1: Розділення (split)                                        │
│  ─────────────────────────                                         │
│  Chunk 1: [1, 2, 3]                                                │
│  Chunk 2: [4, 5, 6]                                                │
│  Chunk 3: [7, 8, 9]                                                │
│  Chunk 4: [10, 11, 12]                                             │
│                                                                     │
│  Крок 2: Розподіл по потоках                                       │
│  ───────────────────────────                                       │
│  Thread 1 ← Chunk 1                                                │
│  Thread 2 ← Chunk 2                                                │
│  Thread 3 ← Chunk 3                                                │
│  Thread 4 ← Chunk 4                                                │
│                                                                     │
│  Крок 3: Паралельне виконання map(|x| x * x)                       │
│  ─────────────────────────────────────────────                     │
│  Thread 1: [1, 4, 9]         ─┐                                    │
│  Thread 2: [16, 25, 36]       ├─► Одночасно!                       │
│  Thread 3: [49, 64, 81]       │                                    │
│  Thread 4: [100, 121, 144]   ─┘                                    │
│                                                                     │
│  Крок 4: Збирання результатів                                      │
│  ─────────────────────────────                                     │
│  Результат: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144]      │
│             (порядок збережено!)                                   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 43.2.4 Три види паралельних ітераторів

Як і звичайні ітератори, паралельні бувають трьох видів залежно від володіння:

| Метод | Володіння | Коли використовувати |
|-------|-----------|----------------------|
| `into_par_iter()` | Забирає володіння (move) | Колекція більше не потрібна |
| `par_iter()` | Іммутабельне посилання (`&T`) | Тільки читання |
| `par_iter_mut()` | Мутабельне посилання (`&mut T`) | Модифікація на місці |

**Постановка задачі:** Продемонструємо всі три види паралельних ітераторів.

```rust
use rayon::prelude::*;

fn main() {
    let mut numbers = vec![1, 2, 3, 4, 5, 6, 7, 8];
    
    // par_iter() — тільки читання
    // Колекція залишається доступною після операції
    let sum: i32 = numbers.par_iter().sum();
    println!("Сума: {}", sum);
    
    // par_iter_mut() — модифікація на місці
    // Кожен елемент множиться на 2
    numbers.par_iter_mut().for_each(|x| *x *= 2);
    println!("Після подвоєння: {:?}", numbers);
    
    // into_par_iter() — споживає колекцію
    // numbers більше не доступна після цього
    let doubled: Vec<i32> = numbers.into_par_iter()
        .map(|x| x * 2)
        .collect();
    println!("Ще раз подвоєно: {:?}", doubled);
    
    // println!("{:?}", numbers);  // Помилка! numbers переміщено
}
```

**Вивід програми:**

```text
Сума: 36
Після подвоєння: [2, 4, 6, 8, 10, 12, 14, 16]
Ще раз подвоєно: [4, 8, 12, 16, 20, 24, 28, 32]
```

### 43.2.5 Work Stealing: магія балансування

Rayon використовує алгоритм **work stealing** (крадіжка роботи) для балансування навантаження. Це елегантне рішення проблеми нерівномірного розподілу роботи.

**Проблема статичного розподілу:**

Якщо розділити роботу статично (Thread 1 бере елементи 1-25, Thread 2 бере 26-50, і т.д.), виникає проблема: деякі елементи можуть оброблятись довше за інші. Потік, що закінчив раніше, простоює.

```rust
Статичний розподіл (погано):
───────────────────────────────────────────────────
Thread 1: [■■■■■■■■■■]──────────────────► (простоює)
Thread 2: [■■■■■■■■■■■■■■■■■■■■■■■■■■■■■]─────────►
Thread 3: [■■■■■■■■■■■■]────────────────► (простоює)
Thread 4: [■■■■■■■■■■■■■■■■■■]──────────► (простоює)
```

**Work Stealing (добре):**

Коли потік завершує свою частину, він "краде" роботу в потоку, що ще працює:

```text
Work Stealing (добре):
───────────────────────────────────────────────────
Thread 1: [■■■■■■■■■■]───[вкрадено від T2]─────────►
Thread 2: [■■■■■■■■■■■■■■■■■]─────────────────────►
Thread 3: [■■■■■■■■■■■■]─[вкрадено від T2]────────►
Thread 4: [■■■■■■■■■■■■■■■■■■]───[вкрадено]───────►
          
Всі потоки зайняті до кінця!
```

Work stealing забезпечує, що всі ядра CPU залишаються зайнятими, навіть якщо час обробки елементів нерівномірний.

---

## 43.3 ОСНОВНІ ОПЕРАЦІЇ RAYON

### 43.3.1 map(): трансформація елементів

`map()` застосовує функцію до кожного елемента паралельно:

**Постановка задачі:** Обчислимо квадрати мільйона чисел паралельно.

```rust
use rayon::prelude::*;

fn main() {
    // Створюємо великий набір даних
    let numbers: Vec<i64> = (0..1_000_000).collect();
    
    // Паралельно обчислюємо квадрати
    let squares: Vec<i64> = numbers
        .par_iter()           // Паралельний ітератор
        .map(|&x| x * x)      // Та сама функція, що й для iter()
        .collect();           // Збираємо результати
    
    println!("Перші 10 квадратів: {:?}", &squares[..10]);
    println!("Останні 10 квадратів: {:?}", &squares[squares.len()-10..]);
}
```

**Вивід:**

```text
Перші 10 квадратів: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
Останні 10 квадратів: [999980000100, ..., 999998000001]
```

**Важлива гарантія:** Порядок результату **збережено**. `squares[0]` завжди відповідає `0²`, `squares[1]` — `1²`, незалежно від того, який потік обробив який елемент.

### 43.3.2 filter(): вибірка елементів

`filter()` залишає тільки елементи, що задовольняють предикат:

**Постановка задачі:** Знайдемо всі прості числа до мільйона паралельно.

```rust
use rayon::prelude::*;

/// Перевірка чи число просте (наївна реалізація)
fn is_prime(n: u64) -> bool {
    if n < 2 { return false; }
    if n == 2 { return true; }
    if n % 2 == 0 { return false; }
    
    let sqrt_n = (n as f64).sqrt() as u64;
    (3..=sqrt_n).step_by(2).all(|i| n % i != 0)
}

fn main() {
    // Знаходимо прості числа паралельно
    let primes: Vec<u64> = (2..1_000_000)
        .into_par_iter()
        .filter(|&n| is_prime(n))
        .collect();
    
    println!("Знайдено {} простих чисел", primes.len());
    println!("Перші 10: {:?}", &primes[..10]);
}
```

**Вивід:**

```text
Знайдено 78498 простих чисел
Перші 10: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]
```

Ця задача ідеально підходить для Rayon: перевірка кожного числа незалежна, і є багато даних.

### 43.3.3 reduce() та fold(): агрегація результатів

Часто потрібно не просто трансформувати елементи, а **звести** їх до одного значення: сума, максимум, конкатенація.

**reduce() — для асоціативних та комутативних операцій:**

**Постановка задачі:** Обчислимо суму квадратів чисел.

```rust
use rayon::prelude::*;

fn main() {
    let sum: i64 = (1..1_000_000_i64)
        .into_par_iter()
        .map(|x| x * x)
        .reduce(
            || 0,           // Початкове значення (identity)
            |a, b| a + b    // Операція об'єднання
        );
    
    println!("Сума квадратів: {}", sum);
}
```

**Як працює reduce паралельно:**

```rust
Елементи: [1, 4, 9, 16, 25, 36, 49, 64]

Thread 1: 1 + 4 = 5          Thread 2: 9 + 16 = 25
Thread 3: 25 + 36 = 61       Thread 4: 49 + 64 = 113

Об'єднання:
(5 + 25) = 30               (61 + 113) = 174

Фінал:
30 + 174 = 204
```

**Важливо:** Операція має бути **асоціативною**: `(a + b) + c = a + (b + c)`. Інакше результат буде непередбачуваним.

**sum() та product() — зручні скорочення:**

```rust
use rayon::prelude::*;

fn main() {
    // sum() — скорочення для reduce(|| 0, |a, b| a + b)
    let sum: i64 = (1..1_000_000_i64).into_par_iter().sum();
    
    // product() — скорочення для reduce(|| 1, |a, b| a * b)
    let factorial_10: u64 = (1..=10).into_par_iter().product();
    
    println!("Сума: {}", sum);
    println!("10!: {}", factorial_10);
}
```

### 43.3.4 for_each(): побічні ефекти

Коли результат не потрібен, але потрібно виконати дію для кожного елемента:

**Постановка задачі:** Оновимо всіх агентів паралельно.

```rust
use rayon::prelude::*;

struct Agent {
    id: u32,
    energy: f64,
}

impl Agent {
    fn update(&mut self) {
        // Симуляція оновлення
        self.energy *= 0.99;  // Втрата енергії
    }
}

fn main() {
    let mut agents: Vec<Agent> = (0..1000)
        .map(|id| Agent { id, energy: 100.0 })
        .collect();
    
    // Оновлюємо всіх агентів паралельно
    agents.par_iter_mut().for_each(|agent| {
        agent.update();
    });
    
    println!("Енергія першого агента: {:.2}", agents[0].energy);
}
```

**Застереження про побічні ефекти:** Якщо ваш `for_each` змінює щось **спільне** (не тільки елемент), потрібна синхронізація! Наприклад, запис у спільний лічильник потребує `Mutex` або `AtomicU64`.

---

## 43.4 КОЛИ ПАРАЛЕЛІЗМ ВИГІДНИЙ

### 43.4.1 Накладні витрати паралелізму

Паралелізм не безкоштовний. Є накладні витрати:

1. **Розподіл роботи**: Час на розділення даних та розподіл по потоках
2. **Синхронізація**: Час на збір результатів
3. **Переключення контексту**: Якщо потоків більше ніж ядер
4. **Кеш-промахи**: Різні потоки працюють з різними частинами пам'яті

Для **малих** колекцій або **легких** операцій послідовний код може бути швидшим!

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ЧАС ВИКОНАННЯ                                     │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  Час                                                                │
│   │                                                                 │
│   │   Послідовний ─────────────────────────────────────             │
│   │                 ╲                                               │
│   │                  ╲    Паралельний                               │
│   │                   ╲  ╱                                          │
│   │                    ╳                                            │
│   │                   ╱                                             │
│   │                  ╱                                              │
│   │    Накладні     ╱                                               │
│   │    витрати ────╱                                                │
│   │               │                                                 │
│   └───────────────┼─────────────────────────────────────►           │
│                   │                          Кількість елементів    │
│                   │                                                 │
│              Точка                                                  │
│              беззбитковості                                         │
│                                                                     │
│  Ліворуч від точки: послідовний код швидший                        │
│  Праворуч від точки: паралельний код швидший                       │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 43.4.2 Правила вибору

**✅ Використовуйте Rayon, коли:**

| Умова | Чому |
|-------|------|
| Багато елементів (тисячі+) | Накладні витрати амортизуються |
| Операція "важка" (>1мкс на елемент) | Паралелізм дає реальний виграш |
| Елементи незалежні | Немає потреби в синхронізації |
| Результат потрібен "одразу" | Паралелізм зменшує латентність |

**❌ Уникайте Rayon, коли:**

| Умова | Чому |
|-------|------|
| Мало елементів (десятки) | Накладні витрати перевищують виграш |
| Операція "легка" (арифметика) | Overhead домінує |
| Елементи залежать один від одного | Потрібна синхронізація, втрачається паралелізм |
| Потрібен строгий порядок виконання | Паралелізм за визначенням недетермінований |
| Вже в async контексті без spawn_blocking | Заблокує async worker |

### 43.4.3 Практичне правило

**"Тисяча мікросекунд"**: Якщо загальний час обробки колекції > 1мс і є > 1000 елементів — варто спробувати Rayon.

**Завжди вимірюйте!** Теоретичні оцінки можуть бути неточними через особливості архітектури.

---

## 43.5 ПОРІВНЯННЯ ПОСЛІДОВНОГО ТА ПАРАЛЕЛЬНОГО КОДУ

### 43.5.1 Бенчмарк: обчислення хешів

**Постановка задачі:** Порівняємо швидкість обчислення SHA-256 хешів для 100,000 рядків послідовно та паралельно.

```rust
use rayon::prelude::*;
use std::time::Instant;
use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};

/// Обчислення "важкого" хешу (симуляція)
fn compute_hash(data: &str) -> u64 {
    let mut hasher = DefaultHasher::new();
    // Робимо обчислення "важчим" через повторення
    for _ in 0..100 {
        data.hash(&mut hasher);
    }
    hasher.finish()
}

fn main() {
    // Генеруємо тестові дані
    let data: Vec<String> = (0..100_000)
        .map(|i| format!("data_item_{}", i))
        .collect();
    
    // Послідовне виконання
    let start = Instant::now();
    let hashes_seq: Vec<u64> = data.iter()
        .map(|s| compute_hash(s))
        .collect();
    let time_seq = start.elapsed();
    
    // Паралельне виконання
    let start = Instant::now();
    let hashes_par: Vec<u64> = data.par_iter()
        .map(|s| compute_hash(s))
        .collect();
    let time_par = start.elapsed();
    
    // Перевірка коректності
    assert_eq!(hashes_seq, hashes_par);
    
    println!("Послідовно: {:?}", time_seq);
    println!("Паралельно: {:?}", time_par);
    println!("Прискорення: {:.2}x", 
        time_seq.as_secs_f64() / time_par.as_secs_f64());
}
```

**Типовий результат (8 ядер):**

```text
Послідовно: 245.32ms
Паралельно: 34.18ms
Прискорення: 7.18x
```

Прискорення близьке до кількості ядер — це ідеальний випадок для data parallelism.

---

## 43.6 ІНТЕГРАЦІЯ RAYON ТА TOKIO

### 43.6.1 Проблема: блокування async runtime

Головна небезпека — викликати Rayon з async контексту напряму:

```rust
// ❌ ПОГАНО: блокує async worker thread!
async fn bad_example(data: Vec<i32>) -> i64 {
    // Цей код виконується в async worker thread
    // par_iter() блокує цей worker на весь час обчислення!
    let result: i64 = data.par_iter()
        .map(|&x| x as i64 * x as i64)
        .sum();
    
    result
}
```

**Чому це погано?**

Tokio має обмежену кількість worker threads (зазвичай = кількість ядер). Якщо один worker заблоковано на CPU-bound операції, він не може обробляти інші async задачі. При достатньому навантаженні — весь async runtime "зависає".

### 43.6.2 Рішення: spawn_blocking

`tokio::task::spawn_blocking` виконує closure в окремому **blocking thread pool**, не блокуючи async workers:

```rust
use tokio::task;
use rayon::prelude::*;

// ✅ ДОБРЕ: CPU-bound робота винесена в blocking pool
async fn good_example(data: Vec<i32>) -> i64 {
    // spawn_blocking виконує closure в окремому пулі потоків
    let result = task::spawn_blocking(move || {
        // Тут безпечно використовувати Rayon
        data.par_iter()
            .map(|&x| x as i64 * x as i64)
            .sum()
    }).await.unwrap();
    
    result
}
```

**Що відбувається:**

1. `spawn_blocking` передає closure в окремий пул потоків (blocking pool)
2. Async worker **не чекає** — він може обробляти інші задачі
3. Коли closure завершується, результат повертається через channel
4. `.await` отримує результат

### 43.6.3 Візуалізація архітектури

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ГІБРИДНА АРХІТЕКТУРА                              │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    TOKIO RUNTIME                             │   │
│  │                                                              │   │
│  │   ┌─────────────────────────────────────────────────────┐   │   │
│  │   │              Async Worker Pool                       │   │   │
│  │   │   ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐  │   │   │
│  │   │   │Worker 1 │ │Worker 2 │ │Worker 3 │ │Worker 4 │  │   │   │
│  │   │   │         │ │         │ │         │ │         │  │   │   │
│  │   │   │  async  │ │  async  │ │  async  │ │  async  │  │   │   │
│  │   │   │  tasks  │ │  tasks  │ │  tasks  │ │  tasks  │  │   │   │
│  │   │   └─────────┘ └─────────┘ └─────────┘ └─────────┘  │   │   │
│  │   │                                                      │   │   │
│  │   │   Призначення: I/O-bound задачі                      │   │   │
│  │   │   (мережа, канали, таймери)                         │   │   │
│  │   └─────────────────────────────────────────────────────┘   │   │
│  │                           │                                  │   │
│  │                           │ spawn_blocking                   │   │
│  │                           ▼                                  │   │
│  │   ┌─────────────────────────────────────────────────────┐   │   │
│  │   │              Blocking Thread Pool                    │   │   │
│  │   │                       +                              │   │   │
│  │   │              RAYON Thread Pool                       │   │   │
│  │   │   ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐  │   │   │
│  │   │   │Thread 1 │ │Thread 2 │ │Thread 3 │ │Thread 4 │  │   │   │
│  │   │   │         │ │         │ │         │ │         │  │   │   │
│  │   │   │CPU-bound│ │CPU-bound│ │CPU-bound│ │CPU-bound│  │   │   │
│  │   │   │ compute │ │ compute │ │ compute │ │ compute │  │   │   │
│  │   │   └─────────┘ └─────────┘ └─────────┘ └─────────┘  │   │   │
│  │   │                                                      │   │   │
│  │   │   Призначення: CPU-bound задачі                      │   │   │
│  │   │   (обчислення, Rayon par_iter)                      │   │   │
│  │   └─────────────────────────────────────────────────────┘   │   │
│  │                                                              │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 43.6.4 Практичний приклад: координатор рою

**Постановка задачі:** Координатор рою має зібрати статуси агентів (I/O), обчислити нові команди (CPU), та розіслати їх (I/O).

```rust
use tokio::sync::mpsc;
use rayon::prelude::*;

#[derive(Clone)]
struct AgentStatus {
    id: u32,
    position: (f64, f64),
    battery: u8,
}

#[derive(Debug)]
struct Command {
    agent_id: u32,
    target: (f64, f64),
}

/// Обчислення оптимальної команди для агента (CPU-bound)
fn compute_optimal_command(status: &AgentStatus) -> Command {
    // Симуляція важких обчислень (A*, оптимізація, тощо)
    std::thread::sleep(std::time::Duration::from_micros(100));
    
    Command {
        agent_id: status.id,
        target: (status.position.0 + 10.0, status.position.1 + 10.0),
    }
}

async fn coordinator_tick(statuses: Vec<AgentStatus>) -> Vec<Command> {
    // Крок 1: CPU-bound обчислення — виносимо в spawn_blocking
    let commands = tokio::task::spawn_blocking(move || {
        // Всередині blocking — використовуємо Rayon
        statuses.par_iter()
            .map(|status| compute_optimal_command(status))
            .collect::<Vec<_>>()
    }).await.expect("Blocking task failed");
    
    commands
}

#[tokio::main]
async fn main() {
    // Симуляція: 1000 агентів
    let statuses: Vec<AgentStatus> = (0..1000)
        .map(|id| AgentStatus {
            id,
            position: (id as f64 * 0.1, id as f64 * 0.2),
            battery: 80,
        })
        .collect();
    
    let start = std::time::Instant::now();
    let commands = coordinator_tick(statuses).await;
    let elapsed = start.elapsed();
    
    println!("Обчислено {} команд за {:?}", commands.len(), elapsed);
    println!("Перша команда: {:?}", commands.first());
}
```

**Вивід (8 ядер):**

```rust
Обчислено 1000 команд за 15.23ms
Перша команда: Some(Command { agent_id: 0, target: (10.0, 10.0) })
```

Послідовно це зайняло б 1000 × 100мкс = 100мс. Паралельно — ~12.5мс (прискорення 8x).

---

## 43.7 ДОДАТКОВІ МОЖЛИВОСТІ RAYON

### 43.7.1 join(): паралельне виконання двох задач

`rayon::join` виконує дві closure паралельно і чекає обох:

**Постановка задачі:** Обчислимо суму та добуток одночасно.

```rust
use rayon::prelude::*;

fn main() {
    let numbers: Vec<i64> = (1..=20).collect();
    
    // Обидва обчислення виконуються паралельно
    let (sum, product) = rayon::join(
        || numbers.par_iter().sum::<i64>(),
        || numbers.par_iter().product::<i64>()
    );
    
    println!("Сума: {}", sum);
    println!("Добуток: {}", product);
}
```

### 43.7.2 scope(): структурований паралелізм

`rayon::scope` дозволяє spawn'ити задачі з гарантією їх завершення:

```rust
use rayon;

fn main() {
    let mut results = vec![0; 4];
    
    rayon::scope(|s| {
        for (i, result) in results.iter_mut().enumerate() {
            s.spawn(move |_| {
                *result = (i + 1) * 10;
            });
        }
    });
    // Тут всі задачі гарантовано завершені
    
    println!("Результати: {:?}", results);
}
```

### 43.7.3 Налаштування пулу потоків

За замовчуванням Rayon створює глобальний пул. Можна налаштувати:

```rust
use rayon::ThreadPoolBuilder;

fn main() {
    // Обмежуємо кількість потоків
    ThreadPoolBuilder::new()
        .num_threads(4)  // Тільки 4 потоки
        .build_global()
        .unwrap();
    
    // Тепер par_iter використовуватиме 4 потоки
}
```

---

## 43.8 ЛАБОРАТОРНА РОБОТА

### Мета роботи

Закріпити практичні навички використання Rayon для паралелізму даних.

### Завдання 1: Обробка зображень (3 бали)

Симулюйте обробку зображень:
- Створіть `Vec<Vec<u8>>` з 1000 "зображень" (кожне — 1000 байт)
- Реалізуйте `process_image(image: &[u8]) -> u64` що обчислює "хеш" (сума байтів)
- Порівняйте час послідовної та паралельної обробки

### Завдання 2: Розрахунок шляхів (4 бали)

Реалізуйте спрощене планування шляхів:
- Структура `Agent { id, position: (f64, f64), target: (f64, f64) }`
- Функція `calculate_path(agent: &Agent) -> Vec<(f64, f64)>` — генерує 100 точок шляху
- Створіть 1000 агентів та обчисліть шляхи паралельно
- Інтегруйте з async через spawn_blocking

### Завдання 3: Статистика рою (3 бали)

Використайте `reduce()` для обчислення:
- Мінімальної, максимальної та середньої позиції X
- Загальної енергії рою
- Кількості агентів у кожному стані

Все — паралельно через Rayon.

---

## 43.9 ТИПОВІ ПОМИЛКИ ТА TROUBLESHOOTING

### 43.9.1 Rayon всередині async без spawn_blocking

**Симптом:** Async система "зависає" під навантаженням.

**Причина:** Rayon блокує async worker threads.

**Рішення:** Завжди використовуйте `tokio::task::spawn_blocking` для Rayon операцій в async контексті.

### 43.9.2 Паралелізм для малих даних

**Симптом:** Паралельний код повільніший за послідовний.

**Причина:** Накладні витрати перевищують виграш.

**Рішення:** Використовуйте Rayon тільки для великих колекцій (тисячі елементів) або важких операцій.

### 43.9.3 Гонки даних при for_each

**Симптом:** Непередбачувані результати при паралельному запису.

**Причина:** Кілька потоків пишуть у спільний ресурс без синхронізації.

**Рішення:** Використовуйте `Mutex`, `AtomicU64`, або перепроєктуйте алгоритм на reduce/fold.

---

## 43.10 РЕЗЮМЕ

### Ключові концепції

**Паралелізм даних** — одна операція на багатьох даних паралельно. Rayon — головний інструмент.

**Паралелізм задач** — різні задачі паралельно. Tokio/async — головний інструмент.

**par_iter()** — заміна для iter(), виконується на всіх ядрах. API майже ідентичний.

**Work Stealing** — алгоритм балансування, вільні потоки "крадуть" роботу.

**spawn_blocking** — міст між async та CPU-bound кодом. Обов'язковий для Rayon в async.

### Правило вибору інструменту

| Питання | Відповідь | Інструмент |
|---------|-----------|------------|
| Програма чекає? | Так | Tokio/async |
| Програма рахує? | Так | Rayon |
| Багато однакових операцій? | Так | Rayon par_iter |
| Різні задачі? | Так | Tokio spawn |

### Патерн інтеграції

```rust
async fn hybrid_operation(data: Vec<T>) -> Result<R, Error> {
    // I/O-bound: async
    let enriched = fetch_additional_data(&data).await?;
    
    // CPU-bound: spawn_blocking + Rayon
    let processed = tokio::task::spawn_blocking(move || {
        enriched.par_iter()
            .map(|item| heavy_computation(item))
            .collect::<Vec<_>>()
    }).await?;
    
    // I/O-bound: async
    save_results(&processed).await?;
    
    Ok(processed)
}
```

---

## 🔗 ЗВ'ЯЗОК З НАСТУПНИМ РОЗДІЛОМ

Ви опанували всі ключові інструменти Частини IV:
- **Async/Await** для I/O-bound операцій
- **Tokio** як async runtime
- **Channels** для комунікації
- **Streams** для потокових даних
- **Actor Model** для структурування системи
- **Rayon** для CPU-bound паралелізму

Тепер час **об'єднати все разом** у **Розділі 44: Практикум — Асинхронний рій v4.0**. Ви побудуєте повноцінну мультиагентну систему:
- Кожен агент — актор
- Комунікація через канали
- CPU-bound обчислення через Rayon
- Координатор керує роєм
- Graceful shutdown всієї системи

Це кульмінація Частини IV — все разом у production-ready архітектурі!

---

> **Наступний розділ:** [Розділ 44: Практикум — Асинхронний рій v4.0](./44_Async_Swarm_v4.md)
