# Частина IV: Асинхронність та масштабування

---

# Розділ 37: Async/Await — Концепції

---

## 📋 Анотація

Ви завершили Частину III, де створили локальний рій агентів на базі потоків операційної системи. Кожен агент — окремий потік, що виконує цикл perceive-decide-act паралельно з іншими. Це елегантне рішення для десятків агентів. Але що робити, коли потрібні сотні? Тисячі? Десятки тисяч?

Потоки операційної системи — це "важка артилерія" паралелізму. Кожен потік споживає від 1 до 8 мегабайтів пам'яті тільки для стеку, не рахуючи даних. Створення потоку займає мікросекунди — здається швидко, але помножте на 10 000, і отримаєте помітну затримку. Перемикання контексту між потоками вимагає збереження та відновлення всіх регістрів процесора, що також коштує дорого.

**Асинхронне програмування** пропонує радикально іншу модель: замість тисячі важких потоків — тисячі "легких" задач у кількох потоках. Задачі кооперативно ділять процесорний час, "поступаючись" під час очікування введення-виведення. Це дозволяє одному серверу обробляти мільйони одночасних з'єднань — те, що здавалось фантастикою ще два десятиліття тому.

Rust реалізує асинхронність через ключові слова `async` та `await`. Але на відміну від інших мов, де асинхронність має приховані витрати (garbage collector, runtime overhead), Rust досягає **нульових накладних витрат** (zero-cost abstraction). Ціна за це — складніша ментальна модель, яку ми детально розберемо в цьому концептуальному розділі.

Цей розділ навмисно зосереджений на **теорії та концепціях**, а не на коді. Ми детально розберемо, що таке Future, як працює async/await під капотом, чому потрібен runtime, і коли асинхронність доречна. Практичне застосування почнеться в наступному розділі з Tokio.

---

## 🎯 Цілі навчання

Після завершення цього розділу ви зможете:

1. **Пояснити** різницю між синхронним, багатопотоковим та асинхронним виконанням
2. **Описати** концепцію Future як "обіцянки майбутнього значення"
3. **Розуміти** ліниву природу Future в Rust на відміну від інших мов
4. **Порівняти** характеристики потоків ОС та асинхронних задач
5. **Обґрунтувати** вибір між потоками та async для різних сценаріїв
6. **Усвідомити** роль runtime та чому стандартна бібліотека Rust його не містить

---

## 📚 Ключові терміни

| Термін | Визначення |
|--------|------------|
| **синхронне виконання** | Модель, де кожна операція блокує виконання до свого завершення; наступна операція починається тільки після закінчення попередньої |
| **асинхронне виконання** | Модель, де операції можуть "поступитись" управлінням під час очікування, дозволяючи іншим операціям виконуватись |
| **Future** | Об'єкт, що представляє значення, яке стане доступним у майбутньому; в Rust реалізується через trait `Future` |
| **polling** | Механізм перевірки готовності Future; runtime періодично "опитує" Future, чи завершився він |
| **await** | Оператор, що позначає точку, де async функція може призупинити виконання та поступитись управлінням |
| **runtime** | Виконавче середовище, що керує плануванням та виконанням асинхронних задач |
| **task (задача)** | Легка одиниця асинхронної роботи; на відміну від потоку, не має власного стеку ОС |
| **cooperative multitasking** | Модель багатозадачності, де задачі самі вирішують, коли поступитись управлінням (на відміну від preemptive, де ОС примусово перемикає) |

---

## 💡 Мотиваційний кейс: Від C10K до C10M

### Проблема C10K: як все починалось

У 1999 році інженер Ден Кегел опублікував статтю "The C10K problem", яка стала поворотним моментом в історії серверного програмування. Питання було просте: як одному серверу обробляти 10 000 одночасних мережевих з'єднань?

На той час це здавалось майже неможливим. Типові сервери використовували модель "один потік на з'єднання" (thread-per-connection). Підрахуємо наслідки:

```rust
10 000 потоків × 1 МБ стеку = 10 ГБ оперативної пам'яті
```

У 1999 році сервер з 10 ГБ RAM був екзотикою. Але навіть якщо пам'ять є, залишається проблема **перемикання контексту**. Коли операційна система перемикає процесор між 10 000 потоками, значна частина процесорного часу витрачається на само перемикання: збереження стану одного потоку, завантаження стану іншого. При тисячах потоків це може з'їсти 30-50% продуктивності.

### Сучасний масштаб: C10M

Сьогодні ми говоримо вже про **C10M** — 10 мільйонів одночасних з'єднань. WhatsApp у 2012 році повідомляв про 2 мільйони з'єднань на один сервер. Discord обробляє мільйони одночасних користувачів. Як це можливо?

Відповідь — асинхронне програмування. Замість 10 мільйонів потоків (що вимагало б 10 ТБ пам'яті) — 10 мільйонів легких задач у кількох десятках потоків. Кожна задача займає кілька сотень байтів замість мегабайтів.

### Чому це важливо для рою БПЛА?

У нашому наскрізному проєкті рій може складатися з сотень або тисяч агентів. Кожен агент потребує:
- Обробки сенсорних даних
- Мережевої комунікації з іншими агентами
- Зв'язку з базовою станцією
- Взаємодії з системою керування

Якщо кожна з цих операцій — окремий потік, ми швидко вичерпаємо ресурси. Асинхронна модель дозволить масштабувати рій до тисяч агентів на одній машині.

---

## 37.1 ТРИ МОДЕЛІ ВИКОНАННЯ КОДУ

### 37.1.1 Синхронна модель: простота ціною ефективності

Синхронне виконання — найпростіша і найінтуїтивніша модель. Код виконується рядок за рядком, кожна операція **блокує** виконання до свого завершення. Тільки після того, як операція повністю завершилась, починається наступна.

Візуалізуємо типовий сценарій — програма, що робить три мережеві запити:

```text
Час ──────────────────────────────────────────────────────────────────►

     ┌─────────────────────────────────────────────────────────────┐
     │                     СИНХРОННА МОДЕЛЬ                        │
     └─────────────────────────────────────────────────────────────┘

Потік: [Запит 1]════════════════════[Обробка 1]
                  ↑ очікування ↑
       [Запит 2]════════════════════[Обробка 2]
                  ↑ очікування ↑
       [Запит 3]════════════════════[Обробка 3]
                  ↑ очікування ↑

       ═════════ = процесор ПРОСТОЮЄ (чекає мережу)
       
Загальний час: T1 + T2 + T3 (сума всіх затримок)
```

**Що відбувається під час очікування?** Коли потік надсилає мережевий запит і чекає відповіді, він знаходиться в стані "blocked" (заблокований). Операційна система знає, що цей потік нічого не може робити, і може перемкнути процесор на інший потік. Але якщо інших потоків немає — процесор буквально простоює.

**Наскільки це неефективно?** Мережева затримка вимірюється мілісекундами (типово 1-100 мс). За цей час процесор з частотою 3 ГГц міг би виконати від 3 до 300 мільйонів інструкцій! Все це витрачається на очікування.

**Коли синхронна модель доречна?**
- Прості скрипти та утиліти
- Програми з мінімумом I/O операцій
- Ситуації, де простота коду важливіша за продуктивність
- Прототипування та навчання

### 37.1.2 Багатопотокова модель: паралелізм через множинність

Логічне рішення проблеми блокування — виконувати кілька операцій паралельно в окремих потоках:

```text
Час ──────────────────────────────────────────────────────────────────►

     ┌─────────────────────────────────────────────────────────────┐
     │                  БАГАТОПОТОКОВА МОДЕЛЬ                      │
     └─────────────────────────────────────────────────────────────┘

Потік 1: [Запит 1]════════════════════[Обробка 1]
Потік 2: [Запит 2]════════════════════[Обробка 2]
Потік 3: [Запит 3]════════════════════[Обробка 3]

         ↑ всі три чекають паралельно ↑

Загальний час: max(T1, T2, T3) — тільки найдовший!
```

Тепер три запити виконуються одночасно, і загальний час — це час найповільнішого запиту, а не сума всіх. Значне покращення!

**Але є ціна:**

| Фактор | Вплив |
|--------|-------|
| **Пам'ять** | Кожен потік потребує окремого стеку (1-8 МБ) |
| **Створення** | Створення потоку — системний виклик, мікросекунди |
| **Перемикання** | Зберігання/відновлення контексту при кожному перемиканні |
| **Синхронізація** | Mutex, RwLock, канали — додаткова складність |
| **Обмеження ОС** | Максимальна кількість потоків обмежена |

**Коли багатопотокова модель доречна?**
- Кількість паралельних задач вимірюється десятками або сотнями
- Задачі є CPU-bound (інтенсивні обчислення)
- Потрібна справжня паралельність на кількох ядрах
- Важлива ізоляція задач (один потік може впасти, інші продовжать)

### 37.1.3 Асинхронна модель: кооперативна багатозадачність

Асинхронна модель вирішує проблему масштабування радикально інакше. Замість того, щоб створювати тисячі потоків, ми виконуємо тисячі **задач** у кількох потоках. Задачі **кооперативно** ділять процесорний час:

```text
Час ──────────────────────────────────────────────────────────────────►

     ┌─────────────────────────────────────────────────────────────┐
     │                   АСИНХРОННА МОДЕЛЬ                         │
     └─────────────────────────────────────────────────────────────┘

Один потік, три задачі:

[Запит 1]→yield→[Запит 2]→yield→[Запит 3]→yield→[Обробка 1]→[Обробка 2]→[Обробка 3]
    │              │              │               ▲           ▲           ▲
    │              │              │               │           │           │
    └──────────────┴──────────────┴───────────────┴───────────┴───────────┘
           Замість очікування — виконуємо наступну задачу!

Загальний час: max(T1, T2, T3) — як у багатопотоковій!
Пам'ять: O(байти) замість O(мегабайти) на задачу!
```

**Як це працює?**

1. Задача 1 надсилає мережевий запит і... замість блокування **поступається** (yield)
2. Runtime переключається на Задачу 2, яка також надсилає запит і поступається
3. Runtime переключається на Задачу 3
4. Коли приходить відповідь для Задачі 1, runtime **відновлює** її виконання

Ключова ідея: **поки одна задача чекає — інші працюють**. Процесор ніколи не простоює.

**Кооперативність vs Преемптивність:**

| Характеристика | Потоки ОС (preemptive) | Async задачі (cooperative) |
|----------------|------------------------|---------------------------|
| Хто перемикає? | Операційна система | Сама задача |
| Коли? | Будь-коли (таймер переривання) | Тільки в точках yield |
| Контроль | ОС вирішує | Програміст вирішує |
| Ризик | Один потік не може заблокувати інші | Одна задача може заблокувати всіх |

### 37.1.4 Метафора ресторану: три моделі обслуговування

Уявімо ресторан з 20 столиками, щоб краще зрозуміти три моделі.

**Синхронна модель: один офіціант на весь ресторан, послідовно**

Офіціант підходить до столика 1, приймає замовлення, йде на кухню, **стоїть і чекає** поки страва готується, несе її, і тільки тоді йде до столика 2. Більшість часу офіціант стоїть і чекає біля кухні.

Результат: 20 столиків обслуговуються за 20 × (час на столик).

**Багатопотокова модель: 20 офіціантів, по одному на столик**

Кожен столик має персонального офіціанта. Всі працюють паралельно. Швидко, але потрібно платити зарплату 20 офіціантам, і вони періодично стикаються біля кухні, створюючи "конфлікти" (аналог синхронізації).

Результат: швидко, але дорого і складно координувати.

**Асинхронна модель: один офіціант, розумно**

Офіціант підходить до столика 1, приймає замовлення, **передає на кухню і одразу йде до столика 2**. Не чекає біля кухні! Приймає замовлення столика 2, передає на кухню, йде до столика 3. Коли кухня сигналізує "страва для столика 1 готова", офіціант забирає і несе.

Результат: один офіціант обслуговує весь зал з мінімальним простоєм.

---

## 37.2 FUTURE: ОБІЦЯНКА МАЙБУТНЬОГО ЗНАЧЕННЯ

### 37.2.1 Що таке Future концептуально?

**Future** (у перекладі — "майбутнє") — це об'єкт, що представляє значення, яке **стане доступним пізніше**. Це не саме значення, а **обіцянка** (promise) його надати.

Аналогія з реальним життям допоможе зрозуміти концепцію:

**Замовлення кави в кав'ярні:**
1. Ви підходите до каси і замовляєте каву
2. Вам дають **номерок** (або пейджер)
3. Номерок — це Future! Це обіцянка, що кава буде готова
4. Ви не стоїте біля каси, чекаючи — ви йдете за столик, читаєте телефон
5. Коли кава готова — вас кличуть (або пейджер вібрує)
6. Ви забираєте каву — Future "вирішився" (resolved)

**Номерок — це не кава.** Але це гарантія, що кава буде. Так само Future — це не значення, а гарантія, що значення з'явиться.

### 37.2.2 Future в Rust: trait Future

У Rust Future — це trait (інтерфейс), який визначає поведінку об'єкта, що представляє майбутнє значення:

```rust
// Спрощена версія (реальний trait трохи складніший)
trait Future {
    type Output;  // Тип результату, який буде отримано
    
    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>;
}

enum Poll<T> {
    Ready(T),    // Значення готове
    Pending,     // Ще не готово, треба почекати
}
```

**Не лякайтесь Pin та Context** — ми розберемо їх пізніше. Зараз важливо зрозуміти логіку:

1. **`Output`** — тип значення, яке Future поверне по завершенню
2. **`poll()`** — метод "опитування": "Ти вже готовий?"
3. **`Poll::Ready(value)`** — "Так, ось результат!"
4. **`Poll::Pending`** — "Ні, ще працюю, спитай пізніше"

### 37.2.3 Ліниві Future: унікальність Rust

Критична відмінність Rust від більшості інших мов: **Future в Rust є лінивим (lazy)**. Це означає, що Future **не виконується**, поки його явно не запустять.

Порівняємо з JavaScript:

**JavaScript (eager Promise):**
```javascript
// Promise починає виконуватись НЕГАЙНО при створенні
const promise = fetch('https://api.example.com/data');
// Запит вже полетів, навіть якщо ми нічого не робимо з promise

// Можемо взагалі не чекати результат — запит все одно виконається
```

**Rust (lazy Future):**
```rust
// Future тільки ОПИСУЄ, що треба зробити
let future = fetch("https://api.example.com/data");
// Запит ще НЕ полетів! Нічого не відбулось!

// Без .await або runtime — код всередині future ніколи не виконається
```

**Чому Rust обрав ліниву модель?**

1. **Zero-cost abstraction**: якщо ви не використовуєте Future, ви не платите за нього
2. **Контроль**: програміст явно вирішує, коли запустити
3. **Композиція**: легше комбінувати Future без побічних ефектів
4. **Скасування**: невиконаний Future можна просто відкинути

**Аналогія: рецепт vs страва**

- JavaScript Promise — це страва, яку почали готувати
- Rust Future — це рецепт, записаний на папері

Рецепт нічого не робить, поки хтось не почне за ним готувати. Ви можете мати тисячу рецептів — жоден не витратить продуктів, поки ви не візьметесь за приготування.

### 37.2.4 Машина станів: що генерує компілятор

Коли ви пишете async функцію, компілятор Rust перетворює її на **машину станів** (state machine). Це ключ до розуміння, як async працює "під капотом".

Розглянемо концептуально:

```rust
// Те, що ви пишете:
async fn fetch_and_process() -> String {
    let data = fetch_data().await;      // Точка призупинення 1
    let processed = process(data).await; // Точка призупинення 2
    processed
}
```

```rust
// Що генерує компілятор (концептуально):
enum FetchAndProcessState {
    Start,
    WaitingForData { fetch_future: FetchDataFuture },
    WaitingForProcess { data: Data, process_future: ProcessFuture },
    Done,
}

impl Future for FetchAndProcess {
    type Output = String;
    
    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<String> {
        loop {
            match self.state {
                Start => {
                    // Починаємо fetch
                    self.state = WaitingForData { 
                        fetch_future: fetch_data() 
                    };
                }
                WaitingForData { fetch_future } => {
                    match fetch_future.poll(cx) {
                        Poll::Pending => return Poll::Pending,
                        Poll::Ready(data) => {
                            self.state = WaitingForProcess {
                                data,
                                process_future: process(data),
                            };
                        }
                    }
                }
                WaitingForProcess { process_future, .. } => {
                    match process_future.poll(cx) {
                        Poll::Pending => return Poll::Pending,
                        Poll::Ready(result) => {
                            self.state = Done;
                            return Poll::Ready(result);
                        }
                    }
                }
                Done => panic!("polled after completion"),
            }
        }
    }
}
```

**Що це означає практично?**

1. **Кожен `.await`** — це потенційна точка призупинення
2. **Стан зберігається** в структурі (не на стеку!)
3. **Розмір Future** = розмір найбільшого стану + дані, що "переживають" await
4. **Немає накладних витрат runtime** — все розгортається на етапі компіляції

Це і є **zero-cost abstraction**: async/await — це синтаксичний цукор для машини станів, яку ви могли б написати вручну (але не хотіли б).

---

## 37.3 ПОРІВНЯННЯ ПОТОКІВ ОС ТА ASYNC ЗАДАЧ

### 37.3.1 Характеристики потоків операційної системи

Потоки ОС (OS threads) — це фундаментальний примітив паралелізму, що існує десятиліттями. Розберемо їхні характеристики:

**Пам'ять:**
- Кожен потік має власний **стек** (stack)
- Типовий розмір стеку: 1 МБ (Linux), 8 МБ (macOS), 1 МБ (Windows)
- Стек виділяється при створенні, навіть якщо не використовується повністю
- Плюс метадані потоку в ядрі ОС

**Створення:**
- Системний виклик до ядра ОС
- Типовий час: 10-30 мікросекунд
- Виділення пам'яті, ініціалізація структур ядра

**Перемикання контексту:**
- Збереження всіх регістрів процесора
- Перемикання таблиць сторінок пам'яті
- Очищення кешів (можливо)
- Типовий час: 1-10 мікросекунд

**Планування:**
- Операційна система вирішує, який потік виконувати
- Preemptive: потік може бути зупинений будь-коли
- Складні алгоритми з пріоритетами, fairness

### 37.3.2 Характеристики асинхронних задач

Async задачі (tasks) — це "легкі потоки" рівня застосунку:

**Пам'ять:**
- Тільки дані, що "переживають" точки await
- Типовий розмір: сотні байтів — кілька кілобайтів
- Виділяється динамічно, росте за потребою

**Створення:**
- Звичайне виділення пам'яті (без системних викликів)
- Типовий час: наносекунди
- Просто алокація структури та ініціалізація полів

**Перемикання:**
- Зміна вказівника на поточну задачу
- Немає перемикання контексту ОС
- Типовий час: десятки наносекунд

**Планування:**
- Runtime (Tokio, async-std) вирішує
- Cooperative: задача сама вирішує, коли поступитись
- Простіші алгоритми, менше накладних витрат

### 37.3.3 Числове порівняння

Порівняємо конкретні числа для 10 000 одночасних задач:

| Характеристика | 10 000 потоків | 10 000 async задач |
|----------------|----------------|-------------------|
| **Пам'ять (стек/дані)** | 10 000 × 1 МБ = **10 ГБ** | 10 000 × 1 КБ = **10 МБ** |
| **Час створення всіх** | 10 000 × 20 мкс = **200 мс** | 10 000 × 100 нс = **1 мс** |
| **Перемикання (1000/сек)** | 1000 × 5 мкс = **5 мс/сек** | 1000 × 50 нс = **50 мкс/сек** |

**Різниця в 1000 разів** — ось чому асинхронність дозволяє масштабуватись до мільйонів з'єднань.

### 37.3.4 Візуальне порівняння

```text
┌─────────────────────────────────────────────────────────────────────┐
│                    ПОРІВНЯННЯ МАСШТАБУ                               │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  1000 ПОТОКІВ                    1 000 000 ASYNC ЗАДАЧ              │
│  ┌───────────────────┐           ┌───────────────────┐              │
│  │ ████████████████  │           │ ░                 │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │  ≈        │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  │ ████████████████  │           │                   │              │
│  └───────────────────┘           └───────────────────┘              │
│        ~1 ГБ RAM                     ~1 ГБ RAM                      │
│                                                                     │
│  █ = 1 МБ (стек потоку)          ░ = ~1 КБ (async задача)          │
│                                                                     │
│  За ту саму пам'ять: 1000x більше задач!                           │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

### 37.3.5 Коли що обирати: таблиця рішень

| Сценарій | Рекомендація | Обґрунтування |
|----------|--------------|---------------|
| **Мережевий сервер з тисячами з'єднань** | Async | Більшість часу — очікування I/O |
| **Обчислення на всіх ядрах CPU** | Потоки (або Rayon) | Потрібна справжня паралельність |
| **Читання тисяч файлів** | Async | I/O-bound, очікування диска |
| **Обробка зображень** | Потоки | CPU-bound, паралелізм |
| **Веб-скрапінг сотень сайтів** | Async | Мережеві затримки домінують |
| **Машинне навчання** | Потоки + GPU | Інтенсивні обчислення |
| **Чат-сервер** | Async | Тисячі користувачів, мало CPU на кожного |
| **Рендеринг відео** | Потоки | CPU-bound обробка кадрів |
| **Рій з 1000 агентів** | Async | Кожен агент = задача, багато I/O |
| **Симуляція фізики** | Потоки (Rayon) | Паралельні обчислення |

---

## 37.4 СИНТАКСИС ASYNC/AWAIT В RUST

### 37.4.1 Ключове слово async: створення Future

Ключове слово `async` перетворює функцію (або блок коду) на **генератор Future**. Це не звичайна функція — вона не виконує код при виклику, а повертає об'єкт Future.

**Постановка задачі:** Продемонструємо, що async функція не виконується при виклику, а лише створює Future.

```rust
// Звичайна функція — виконується при виклику
fn regular_function() -> i32 {
    println!("Виконується!");  // Це виведеться при виклику
    42
}

// Async функція — НЕ виконується при виклику, повертає Future
async fn async_function() -> i32 {
    println!("Виконується!");  // Це виведеться тільки при .await
    42
}

fn demonstrate() {
    let result = regular_function();  // "Виконується!" виводиться
    // result = 42
    
    let future = async_function();    // Нічого не виводиться!
    // future — це об'єкт типу impl Future<Output = i32>
    // Код всередині ще не виконувався
    
    // Тільки при .await (у async контексті) код виконається
}
```

**Як працює цей код:**

1. `regular_function()` — виклик функції одразу виконує її тіло, println! спрацьовує, повертається 42
2. `async_function()` — виклик НЕ виконує тіло! Він створює структуру (Future), що **описує** майбутнє виконання
3. Future — це "рецепт" або "план дій", записаний у структурі даних
4. Без `.await` або runtime цей план ніколи не буде виконано

### 37.4.2 Оператор .await: точка призупинення

Оператор `.await` робить дві речі:

1. **Запускає виконання** Future (якщо ще не запущений)
2. **Призупиняє** поточну async функцію, поки Future не завершиться

**Постановка задачі:** Покажемо, як .await призупиняє виконання та дозволяє іншим задачам працювати.

```rust
async fn make_coffee() -> String {
    println!("1. Починаємо варити каву...");
    
    // .await — точка призупинення
    // Тут функція може "заснути", поки кава готується
    simulate_brewing().await;
    
    println!("2. Кава готова!");
    "Еспресо".to_string()
}

async fn make_toast() -> String {
    println!("1. Починаємо готувати тост...");
    
    simulate_toasting().await;  // Інша точка призупинення
    
    println!("2. Тост готовий!");
    "Тост з маслом".to_string()
}

async fn breakfast() {
    println!("=== Сніданок ===");
    
    // Послідовно (НЕ паралельно):
    let coffee = make_coffee().await;   // Чекаємо каву
    let toast = make_toast().await;     // Потім чекаємо тост
    
    println!("Готово: {} та {}", coffee, toast);
}
```

**Як працює цей код:**

1. При виклику `make_coffee().await`, виконання `breakfast` призупиняється
2. Runtime може виконувати інші задачі, поки кава "готується"
3. Коли `simulate_brewing()` завершиться, `breakfast` відновиться
4. Потім те саме для `make_toast`

**Важливо:** У цьому прикладі кава та тост готуються **послідовно**, не паралельно. Паралельне виконання потребує спеціальних конструкцій (join!, spawn), які ми розглянемо в наступному розділі.

### 37.4.3 Async блоки: анонімні Future

Окрім async функцій, можна створювати анонімні Future за допомогою async блоків:

**Постановка задачі:** Показати використання async блоків для створення Future "на місці", без окремої функції.

```rust
async fn example() {
    // Async блок створює Future без окремої функції
    let future = async {
        println!("Це код всередині async блоку");
        calculate_something().await;
        42  // Значення, що повернеться
    };
    
    // future має тип impl Future<Output = i32>
    
    // Виконуємо:
    let result = future.await;  // result = 42
}
```

**Коли використовувати async блоки:**

- Коли Future потрібен тільки в одному місці
- Для "захоплення" змінних з контексту (closure-like)
- Для комбінування кількох операцій в один Future

### 37.4.4 Обмеження: await тільки в async контексті

Оператор `.await` можна використовувати **тільки** всередині async функцій або async блоків. Це фундаментальне обмеження:

```rust
// ❌ НЕ КОМПІЛЮЄТЬСЯ
fn regular_function() {
    let result = async_operation().await;  // Помилка!
    // error: `await` is only allowed inside `async` functions and blocks
}

// ✅ ПРАВИЛЬНО
async fn async_function() {
    let result = async_operation().await;  // OK
}

// ✅ ТАКОЖ ПРАВИЛЬНО
fn another_approach() {
    let future = async {
        async_operation().await  // OK — всередині async блоку
    };
    // Але future ще треба якось виконати (runtime)
}
```

**Чому таке обмеження?** Код до та після `.await` — це різні "стани" машини станів. Компілятору потрібен async контекст, щоб згенерувати цю машину станів.

---

## 37.5 RUNTIME: ВИКОНАВЕЦЬ ASYNC КОДУ

### 37.5.1 Чому потрібен runtime?

Ви написали async функцію. Вона повертає Future. Але Future — лінивий, він нічого не робить сам. Хтось має:

1. **Викликати `poll()`** на Future
2. **Відстежувати**, коли Future готовий продовжити
3. **Перемикатись** між задачами
4. **Реагувати** на події (мережа, таймери, файли)

Цей "хтось" — **runtime** (виконавче середовище).

**Аналогія:** Future — це рецепт страви. Runtime — це кухар, що читає рецепт і виконує кроки. Без кухаря рецепт залишиться папірцем.

### 37.5.2 Чому стандартна бібліотека Rust не містить runtime?

Це свідоме рішення дизайну Rust, що відрізняє його від інших мов:

| Мова | Runtime |
|------|---------|
| JavaScript (Node.js) | V8 event loop — вбудований |
| Python | asyncio — в стандартній бібліотеці |
| Go | Goroutine scheduler — вбудований в мову |
| C# | Task scheduler — в .NET runtime |
| **Rust** | **Немає в std — обираєте самі** |

**Причини відсутності runtime в std:**

1. **"Pay for what you use"**: не всім програмам потрібен async. Embedded системи, CLI утиліти можуть обійтись без нього.

2. **Різні потреби**: веб-сервер, real-time гра, embedded контролер потребують різних runtime з різними характеристиками.

3. **Інновації**: окремі runtime можуть еволюціонувати швидше за std, експериментувати.

4. **Zero-cost**: якщо ви не використовуєте async, ви не платите за runtime.

**Популярні runtime для Rust:**

| Runtime | Характеристика | Використання |
|---------|----------------|--------------|
| **Tokio** | Найпопулярніший, багатопотоковий | Веб-сервери, мережеві застосунки |
| **async-std** | Схожий API на std | Загальне використання |
| **smol** | Мінімалістичний | Коли потрібен маленький footprint |
| **embassy** | Для embedded | Мікроконтролери |

У цьому підручнику ми використовуватимемо **Tokio** — найпоширеніший вибір для серверних застосунків.

### 37.5.3 Як працює runtime: концептуальна схема

```text
┌─────────────────────────────────────────────────────────────────────┐
│                         ASYNC RUNTIME                                │
├─────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                     ПЛАНУВАЛЬНИК (Scheduler)                │   │
│  │                                                             │   │
│  │  Черга готових задач:  [Task A] [Task B] [Task C] ...      │   │
│  │                                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                              │                                      │
│                              ▼                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                   WORKERS (потоки ОС)                       │   │
│  │                                                             │   │
│  │  Worker 1: виконує Task A                                  │   │
│  │  Worker 2: виконує Task B                                  │   │
│  │  Worker 3: чекає нових задач                               │   │
│  │  Worker 4: виконує Task C                                  │   │
│  │                                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                              │                                      │
│                              ▼                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                   РЕАКТОР (I/O Event Loop)                  │   │
│  │                                                             │   │
│  │  Відстежує:                                                 │   │
│  │  - Мережеві сокети (epoll/kqueue/iocp)                     │   │
│  │  - Таймери                                                  │   │
│  │  - Файлові дескриптори                                      │   │
│  │                                                             │   │
│  │  Коли подія відбулась → будить відповідну Task             │   │
│  │                                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

**Компоненти runtime:**

1. **Планувальник (Scheduler)**: вирішує, яку задачу виконувати наступною. Підтримує чергу готових задач.

2. **Workers**: реальні потоки ОС, що виконують код задач. Зазвичай кількість workers = кількість ядер CPU.

3. **Реактор (I/O Event Loop)**: відстежує зовнішні події (мережа, таймери). Коли подія відбувається — будить відповідну задачу.

### 37.5.4 Алгоритм виконання Future

Спрощений алгоритм того, як runtime виконує Future:

```text
1. Runtime отримує Future для виконання

2. LOOP:
   a. Викликає future.poll()
   
   b. Якщо poll() повернув Ready(value):
      - Задача завершена!
      - Повертає value
      - EXIT LOOP
      
   c. Якщо poll() повернув Pending:
      - Задача ще не готова
      - Future зареєструвала "waker" — спосіб розбудити себе
      - Переходить до іншої задачі
      
   d. Коли waker спрацює (подія відбулась):
      - Задача повертається в чергу готових
      - GOTO 2
```

**Ключовий момент:** Runtime не робить "busy waiting" (постійне опитування). Він використовує механізми ОС (epoll на Linux, kqueue на macOS, IOCP на Windows) для **ефективного очікування** подій без витрат CPU.

---

## 37.6 ПОРІВНЯННЯ З ІНШИМИ МОВАМИ

### 37.6.1 JavaScript: Event Loop та Promise

JavaScript має вбудований event loop та eager Promise:

```javascript
// JavaScript
async function fetchData() {
    // Promise створюється і ОДРАЗУ починає виконання
    const response = await fetch('/api/data');
    return response.json();
}

// Виклик без await — запит все одно відправиться
const promise = fetchData();  // Запит полетів!
```

**Ключові відмінності від Rust:**
- Promise — eager (негайно виконується)
- Один потік (single-threaded)
- Garbage collector для пам'яті
- Runtime вбудований у V8/SpiderMonkey

### 37.6.2 Go: Goroutines

Go має goroutines — легкі потоки з власним планувальником:

```go
// Go
func fetchData() string {
    resp, _ := http.Get("/api/data")
    // ...
    return result
}

// Запуск goroutine
go fetchData()  // Виконується паралельно
```

**Ключові відмінності від Rust:**
- Implicit concurrency (не треба async/await)
- Runtime завжди присутній
- Goroutines можуть бути preempted
- Garbage collector для пам'яті

### 37.6.3 Python: asyncio

Python має asyncio з async/await синтаксисом:

```python
# Python
async def fetch_data():
    async with aiohttp.ClientSession() as session:
        response = await session.get('/api/data')
        return await response.json()

# Запуск
asyncio.run(fetch_data())
```

**Ключові відмінності від Rust:**
- GIL обмежує паралелізм
- Runtime в стандартній бібліотеці
- Dynamic typing, повільніше
- Garbage collector

### 37.6.4 Унікальність Rust

| Характеристика | Rust | JavaScript | Go | Python |
|----------------|------|------------|-----|--------|
| **Future/Promise** | Lazy | Eager | Implicit | Lazy |
| **Runtime** | Вибір користувача | Вбудований | Вбудований | Стандартна бібл. |
| **Модель пам'яті** | Ownership | GC | GC | GC |
| **Zero-cost** | ✅ | ❌ | ❌ | ❌ |
| **Безпека потоків** | Compile-time | N/A | Runtime | GIL |

**Що робить Rust унікальним:**

1. **Zero-cost abstraction**: async/await компілюється в оптимальний код без накладних витрат
2. **Вибір runtime**: можна обрати або написати власний
3. **Ownership працює з async**: Send/Sync traits гарантують безпеку
4. **Без GC**: передбачуваний час виконання, важливо для real-time систем

---

## 37.7 ТИПОВІ ПОМИЛКИ ТА ПІДВОДНІ КАМЕНІ

### 37.7.1 Блокуючий код в async контексті

Найпоширеніша помилка — використання блокуючих операцій в async коді.

**Постановка проблеми:** Покажемо, як блокуючий код "отруює" весь runtime.

```rust
// ❌ НЕПРАВИЛЬНО: блокуємо весь worker потік
async fn bad_example() {
    // std::thread::sleep — БЛОКУЮЧА операція
    // Весь worker потік заблокований на 5 секунд
    // Інші задачі на цьому worker не можуть виконуватись!
    std::thread::sleep(Duration::from_secs(5));
    
    println!("Прокинувся");
}

// ✅ ПРАВИЛЬНО: використовуємо async версію
async fn good_example() {
    // tokio::time::sleep — ASYNC операція
    // Задача поступається, інші можуть працювати
    tokio::time::sleep(Duration::from_secs(5)).await;
    
    println!("Прокинувся");
}
```

**Як працює цей код:**

У поганому прикладі `std::thread::sleep` — це звичайна синхронна функція. Вона блокує потік ОС. Якщо у Tokio 4 worker потоки, і всі 4 задачі зроблять `std::thread::sleep`, весь runtime зависне.

У правильному прикладі `tokio::time::sleep` повертає Future. При `.await` задача реєструє таймер і поступається. Worker може виконувати інші задачі. Коли таймер спрацює, задача прокинеться.

**Правило:** В async коді використовуйте тільки async версії операцій!

### 37.7.2 CPU-bound робота в async

Async оптимізований для I/O-bound задач (очікування). CPU-bound обчислення (інтенсивна робота процесора) блокують worker:

**Постановка проблеми:** Продемонструємо правильний підхід до CPU-bound роботи.

```rust
// ❌ НЕПРАВИЛЬНО: важкі обчислення блокують worker
async fn bad_cpu_work() {
    // Обчислення мільйонного простого числа займає секунди
    // Весь цей час worker не може виконувати інші задачі
    let result = calculate_millionth_prime();
    println!("Результат: {}", result);
}

// ✅ ПРАВИЛЬНО: виносимо CPU-bound роботу
async fn good_cpu_work() {
    // spawn_blocking виконує код в окремому пулі потоків,
    // призначеному для блокуючих операцій
    let result = tokio::task::spawn_blocking(|| {
        calculate_millionth_prime()
    }).await.expect("Task failed");
    
    println!("Результат: {}", result);
}
```

**Як працює цей код:**

`spawn_blocking` створює задачу в **окремому пулі потоків**, призначеному для блокуючих операцій. Це не ті ж worker потоки, що виконують async код. Таким чином:
- Async workers залишаються вільними
- CPU-bound робота виконується паралельно
- Коли робота завершена, результат повертається в async контекст

### 37.7.3 Future не виконується без .await

Ще одна типова помилка для новачків — забути `.await`:

**Постановка проблеми:** Показати, що Future без .await — це "мертвий код".

```rust
async fn important_work() {
    println!("Роблю важливу роботу!");
    save_to_database().await;
}

async fn buggy_function() {
    important_work();  // ⚠️ УВАГА: без .await!
    // Future створено, але НЕ виконано
    // "Роблю важливу роботу!" ніколи не виведеться
    // Дані не збережуться в базу
    
    println!("Готово!");  // Це виведеться, але робота не зроблена
}

async fn correct_function() {
    important_work().await;  // ✅ Тепер код виконається
    println!("Готово!");
}
```

**Як працює цей код:**

Виклик `important_work()` без `.await` просто створює Future (структуру даних). Цей Future одразу відкидається (drop), оскільки результат нікуди не присвоюється. Код всередині функції ніколи не виконається.

Компілятор Rust видасть попередження: `unused implementer of Future that must be used`. **Завжди звертайте увагу на попередження компілятора!**

### 37.7.4 Неправильне розуміння паралелізму

Async/await за замовчуванням виконує код **послідовно**, не паралельно:

```rust
async fn sequential() {
    // Ці операції виконуються ПОСЛІДОВНО
    let a = fetch_a().await;   // Чекаємо завершення
    let b = fetch_b().await;   // Потім чекаємо завершення
    let c = fetch_c().await;   // Потім чекаємо завершення
    
    // Загальний час = час_a + час_b + час_c
}

async fn parallel() {
    // Для паралельного виконання потрібен join! або spawn
    let (a, b, c) = tokio::join!(
        fetch_a(),
        fetch_b(),
        fetch_c()
    );
    
    // Загальний час = max(час_a, час_b, час_c)
}
```

**Паралельне виконання async задач** вимагає явних конструкцій — `join!`, `select!`, `spawn`. Ми детально розглянемо їх у розділі про Tokio.

---

## 37.8 ЛАБОРАТОРНА РОБОТА

### Мета роботи

Закріпити концептуальне розуміння async/await без написання коду. Цей розділ — теоретичний, практика буде в наступному.

### Теоретичні питання (10 балів)

**Питання 1 (2 бали):** Поясніть своїми словами різницю між "lazy Future" в Rust та "eager Promise" в JavaScript. Наведіть аналогію з реального життя.

**Питання 2 (2 бали):** Чому потоки ОС споживають більше пам'яті, ніж async задачі? Що конкретно займає цю пам'ять?

**Питання 3 (2 бали):** Уявіть веб-сервер, що обробляє 10 000 одночасних HTTP-запитів. Порівняйте два підходи:
- Thread-per-request (один потік на запит)
- Async (всі запити в async задачах)

Оцініть приблизне споживання пам'яті для кожного підходу.

**Питання 4 (2 бали):** Чому `std::thread::sleep` не можна використовувати в async функції? Що станеться, якщо все ж використати?

**Питання 5 (2 бали):** Rust не має runtime в стандартній бібліотеці, на відміну від Go, JavaScript, Python. Назвіть дві переваги та два недоліки такого рішення.

### Завдання на аналіз коду

**Завдання 1:** Визначте проблеми в наступному коді та поясніть, що піде не так:

```rust
async fn process_files() {
    let file1 = std::fs::read_to_string("file1.txt").unwrap();
    let file2 = std::fs::read_to_string("file2.txt").unwrap();
    println!("Прочитано {} та {} байт", file1.len(), file2.len());
}
```

**Завдання 2:** Поясніть, чому наступний код не виконає жодної "важливої роботи":

```rust
async fn main_task() {
    for i in 0..10 {
        do_important_work(i);  // async функція
    }
    println!("Всі завдання створені!");
}
```

---

## 37.9 РЕЗЮМЕ

### Ключові концепції

**Три моделі виконання:**
- **Синхронна**: послідовно, з блокуванням — проста, але неефективна
- **Багатопотокова**: паралельно в потоках ОС — ефективна, але дорога
- **Асинхронна**: кооперативно в задачах — ефективна і масштабована

**Future в Rust:**
- Представляє значення, що стане доступним у майбутньому
- **Лінивий** — не виконується без `.await` або runtime
- Компілятор перетворює async функцію на машину станів
- Zero-cost abstraction — немає накладних витрат runtime

**Async/await синтаксис:**
- `async fn` — створює функцію, що повертає Future
- `.await` — точка призупинення, де задача може поступитись
- Await можна використовувати тільки в async контексті

**Runtime:**
- Виконує Future, керує задачами
- Не входить в std — обираєте самі (Tokio, async-std, smol)
- Складається з планувальника, workers, реактора

### Правила для запам'ятовування

| Правило | Пояснення |
|---------|-----------|
| Async — для I/O-bound | Мережа, диск, таймери — де багато очікування |
| Потоки — для CPU-bound | Інтенсивні обчислення, паралелізм на ядрах |
| В async — тільки async операції | `tokio::time::sleep`, не `std::thread::sleep` |
| CPU-bound в async — через `spawn_blocking` | Не блокуйте async workers |
| Future без `.await` — не виконується | Завжди перевіряйте попередження компілятора |
| `.await` ≠ паралельність | Для паралельності потрібен `join!` або `spawn` |

### Таблиця вибору підходу

| Ситуація | Підхід |
|----------|--------|
| Тисячі одночасних мережевих з'єднань | **Async** |
| Паралельна обробка даних на всіх ядрах | **Потоки (Rayon)** |
| Веб-сервер | **Async (Tokio)** |
| Рендеринг відео | **Потоки** |
| Рій з тисяч агентів | **Async** |
| Машинне навчання | **Потоки + GPU** |
| CLI утиліта з кількома HTTP запитами | **Async** |
| Симуляція фізики в реальному часі | **Потоки** |

---

## 🔗 ЗВ'ЯЗОК З НАСТУПНИМ РОЗДІЛОМ

Ви зрозуміли концепції async/await, але поки що не писали жодного робочого async коду. Це навмисно — спочатку розуміння, потім практика.

У **Розділі 38: Tokio — Async Runtime** ви:

- Встановите та налаштуєте Tokio у проєкті
- Напишете перші робочі async програми
- Зрозумієте макрос `#[tokio::main]`
- Створите паралельні async задачі з `spawn` та `join!`
- Використаєте async таймери, канали та I/O
- Побачите, як рій агентів масштабується з потоків до async задач

Переходимо від теорії до практики!

---

> **Наступний розділ:** [Розділ 38: Tokio — Async Runtime](./38_Tokio.md)
