# Розділ 34: Arc та Mutex — потокобезпечний спільний стан

## Вступ: ізольовані потоки недостатні

У попередньому розділі ви створили перші багатопотокові програми, але зіткнулись з фундаментальним обмеженням: кожен потік жив **ізольовано**, без доступу до спільних даних. Це схоже на команду працівників, де кожен працює у власній кімнаті без можливості спілкуватись.

Для реального рою агентів така ізоляція неприйнятна:
- Агенти мають **ділити карту світу** — інакше кожен "відкриватиме" вже відомі об'єкти
- Вони мають **координувати дії** — інакше два агенти летітимуть до однієї цілі
- Вони мають **збирати спільну статистику** — інакше неможливий аналіз місії

Як організувати спільний доступ до даних, не створюючи хаосу?

Rust пропонує два взаємодоповнюючі інструменти:
- **Arc** — для спільного володіння між потоками
- **Mutex** — для безпечної координації доступу

Разом вони утворюють патерн `Arc<Mutex<T>>` — стандарт багатопотокового програмування в Rust.

---

## 34.1 Чому Rc не працює між потоками

### Анатомія операції інкременту

Коли ви пишете просту операцію `count += 1`, на рівні процесора це **три окремі кроки**:

1. **Читання**: завантажити значення з пам'яті в регістр
2. **Модифікація**: додати одиницю
3. **Запис**: зберегти результат назад у пам'ять

В однопотоковій програмі це не проблема. Але в багатопотоковій операційна система може **перемкнути контекст** між будь-якими двома кроками.

### Сценарій гонки даних

**Постановка задачі:** Показати, як виникає data race при паралельному інкременті.

```
Два потоки намагаються збільшити лічильник (початково = 5):

Час    Потік A                    Потік B              Пам'ять
────────────────────────────────────────────────────────────────
t1     Читає значення 5           (очікує)             5
t2     (перемикання!)             Читає значення 5     5
t3     Обчислює 5 + 1 = 6         Обчислює 5 + 1 = 6   5
t4     Записує 6                  (очікує)             6
t5     (завершено)                Записує 6            6

Очікували: 7
Отримали:  6  ← Одне оновлення ЗАГУБИЛОСЬ!
```

Обидва потоки "успішно" збільшили лічильник, але результат неправильний. Це **data race** — гонка за дані.

### Наслідки для Rc

Rc використовує внутрішній лічильник для відстеження посилань. Кожен `Rc::clone()` збільшує лічильник, кожен `drop()` — зменшує. Якщо ці операції не атомарні:

**Сценарій 1: Передчасне звільнення**
Лічильник через гонку стає 0 раніше, ніж треба → пам'ять звільняється → інші потоки мають use-after-free.

**Сценарій 2: Витік пам'яті**
Лічильник ніколи не досягає 0 → пам'ять ніколи не звільняється.

**Постановка задачі:** Показати, що Rc не компілюється у багатопотоковому контексті.

```rust
use std::rc::Rc;
use std::cell::RefCell;
use std::thread;

fn main() {
    let counter = Rc::new(RefCell::new(0));
    let counter_clone = Rc::clone(&counter);
    
    // ❌ Цей код НЕ скомпілюється!
    thread::spawn(move || {
        *counter_clone.borrow_mut() += 1;
    });
}
```

**Помилка компіляції:**
```
error[E0277]: `Rc<RefCell<i32>>` cannot be sent between threads safely
```

Rust **захистив нас** від серйозної помилки ще до запуску програми.

---

## 34.2 Arc: атомарний лічильник посилань

### Що таке атомарні операції

**Атомарна операція** — це операція, яка виконується як **єдине ціле**, без можливості переривання. Процесор гарантує, що інші ядра не побачать проміжного стану.

Атомарний інкремент — це не три окремі операції, а одна неподільна. Процесор має спеціальні інструкції для цього (на x86 — `lock add`).

Атомарні операції **повільніші** за звичайні — процесор координує доступ між ядрами. Але вони **гарантовано безпечні**.

### Arc — Rc з атомарним лічильником

**Arc** (Atomically Reference Counted) — версія Rc, де лічильник оновлюється атомарно. API ідентичний Rc, різниця — у внутрішній реалізації.

| Характеристика | Rc<T> | Arc<T> |
|----------------|-------|--------|
| Операції лічильника | Звичайні | Атомарні |
| Накладні витрати | Мінімальні | Вищі |
| Реалізує Send | ❌ Ні | ✅ Так |
| Реалізує Sync | ❌ Ні | ✅ Так (якщо T: Sync) |
| Використання | Однопотоковий | Багатопотоковий |

**Правило вибору**: однопотоковий код → Rc (швидше); багатопотоковий → Arc (безпечно).

### Базове використання Arc

**Постановка задачі:** Передати дані кільком потокам через Arc.

```rust
use std::sync::Arc;
use std::thread;

fn main() {
    // Створюємо Arc, що володіє вектором
    let data = Arc::new(vec![1, 2, 3, 4, 5]);
    
    println!("Початковий strong_count: {}", Arc::strong_count(&data));
    
    let mut handles = vec![];
    
    for i in 0..3 {
        // ВАЖЛИВО: клонуємо Arc ПЕРЕД spawn
        // Клонування Arc дешеве — копіюється вказівник,
        // атомарний лічильник збільшується на 1
        let data_clone = Arc::clone(&data);
        
        println!("Після clone {}: strong_count = {}", 
                 i, Arc::strong_count(&data));
        
        let handle = thread::spawn(move || {
            // Кожен потік має свій Arc, але всі вказують
            // на ті самі дані в heap
            println!("Потік {}: дані = {:?}", i, *data_clone);
            
            // Можемо читати через Deref
            let sum: i32 = data_clone.iter().sum();
            println!("Потік {}: сума = {}", i, sum);
        });
        
        handles.push(handle);
    }
    
    // Чекаємо завершення всіх потоків
    for handle in handles {
        handle.join().unwrap();
    }
    
    // Оригінальний Arc все ще валідний
    println!("Після завершення потоків: {:?}", data);
    println!("Фінальний strong_count: {}", Arc::strong_count(&data));
}
```

**Як це працює:**

1. `Arc::new(vec![...])` — створюємо Arc з вектором на heap
2. `Arc::clone(&data)` — створюємо нову "ручку" до тих самих даних
3. Кожен потік отримує свій Arc через move
4. Після завершення потоків їхні Arc знищуються, лічильник зменшується
5. Оригінальний Arc залишається, дані ще існують

### Що Arc НЕ дає

Arc вирішує проблему спільного **володіння**, але **не мутації**. Arc дає тільки `&T` — незмінне посилання:

```rust
let counter = Arc::new(0);
let counter_clone = Arc::clone(&counter);

// ❌ Це не скомпілюється!
// Arc<i32> дає &i32, а потрібно &mut i32
// *counter_clone += 1;  // Помилка!
```

Для мутації потрібен **Mutex**.

---

## 34.3 Mutex: взаємне виключення

### Філософія взаємного виключення

Уявіть офіс з однією переговорною кімнатою. Щоб уникнути хаосу, є правило: **хто взяв ключ — той користується кімнатою**. Поки ключ у когось, інші чекають біля дверей.

**Mutex** (mutual exclusion) працює так само:
- Щоб отримати доступ до даних, потік **захоплює** mutex
- Поки mutex захоплений, інші потоки **блокуються**
- Після роботи потік **відпускає** mutex
- Наступний потік у черзі отримує доступ

Це гарантує: в будь-який момент тільки **один потік** має доступ до даних.

### Mutex у Rust: безпека через типи

У багатьох мовах mutex — окремий об'єкт, і програміст має пам'ятати, який mutex захищає які дані. Rust вирішує це елегантно: `Mutex<T>` **огортає** дані.

Ви **не можете** отримати доступ до даних, не захопивши mutex — це неможливо на рівні типів.

**Постановка задачі:** Показати базову роботу з Mutex.

```rust
use std::sync::Mutex;

fn main() {
    // Mutex огортає значення 5
    // Дістатись до 5 можна ТІЛЬКИ через mutex
    let m = Mutex::new(5);
    
    println!("Mutex створено: {:?}", m);
    
    {
        // lock() захоплює mutex і повертає MutexGuard
        // MutexGuard — "розумна обгортка" для доступу до даних
        let mut guard = m.lock().unwrap();
        
        println!("Lock захоплено");
        
        // Через guard можемо читати і змінювати
        // Deref та DerefMut дозволяють працювати як з &mut T
        println!("Значення до зміни: {}", *guard);
        *guard += 1;
        println!("Значення після зміни: {}", *guard);
        
        // Коли guard виходить зі scope — mutex автоматично
        // звільняється. Це RAII в дії!
    }
    
    println!("Lock звільнено");
    
    // Тепер mutex вільний
    println!("Фінальний стан: {:?}", m);
}
```

**Як це працює:**

1. `Mutex::new(5)` — огортаємо дані в mutex
2. `m.lock()` — блокуємо потік, поки не отримаємо доступ
3. `unwrap()` — обробляємо можливу помилку (отруєний mutex)
4. `*guard` — доступ до даних через Deref
5. Вихід з блоку `{}` → guard знищується → mutex звільняється

### MutexGuard: розумний охоронець

`MutexGuard<T>` — це повноцінний smart pointer:

| Trait | Що дає |
|-------|--------|
| `Deref<Target = T>` | Читання через `*guard` |
| `DerefMut` | Зміна через `*guard` |
| `Drop` | Автоматичне звільнення mutex |

Властивість `Drop` критична. У C/C++ типова помилка — забути `unlock()`. У Rust **неможливо**: коли guard виходить зі scope (кінець блоку, return, паніка) — mutex звільняється автоматично.

### Отруєний mutex

`lock()` повертає `Result`, бо mutex може бути **отруєним**:

```rust
let guard = m.lock().unwrap();  // unwrap може паникувати!
```

Mutex стає отруєним, якщо потік, що тримав lock, **запанікував**. Rust припускає: дані можуть бути в неконсистентному стані.

**Для навчального коду** `unwrap()` прийнятний. **Для production:**

```rust
let guard = match m.lock() {
    Ok(guard) => guard,
    Err(poisoned) => {
        eprintln!("Увага: mutex отруєний, відновлюємо...");
        poisoned.into_inner()  // Продовжуємо попри отруєння
    }
};
```

---

## 34.4 Комбінування Arc та Mutex

### Патерн Arc<Mutex<T>>

Тепер ми маємо обидва компоненти:
- **Arc** — кілька потоків володіють одними даними
- **Mutex** — безпечна мутація цих даних

Комбінація `Arc<Mutex<T>>` — стандартний патерн:

**Постановка задачі:** 10 потоків інкрементують спільний лічильник.

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // Створюємо спільний лічильник
    // Arc — щоб кілька потоків могли володіти
    // Mutex — щоб могли безпечно змінювати
    let counter = Arc::new(Mutex::new(0));
    
    let mut handles = vec![];
    
    for i in 0..10 {
        // Клонуємо Arc — кожен потік отримує свою "ручку"
        let counter_clone = Arc::clone(&counter);
        
        let handle = thread::spawn(move || {
            // Захоплюємо mutex
            let mut num = counter_clone.lock().unwrap();
            
            // Безпечно змінюємо значення
            *num += 1;
            
            println!("Потік {}: лічильник = {}", i, *num);
            
            // При виході з блоку guard знищується,
            // mutex звільняється
        });
        
        handles.push(handle);
    }
    
    // Чекаємо всіх потоків
    for handle in handles {
        handle.join().unwrap();
    }
    
    // Результат ЗАВЖДИ 10 — незалежно від порядку виконання!
    println!("Фінальний результат: {}", *counter.lock().unwrap());
}
```

**Як це працює:**

1. **Створення**: `Arc::new(Mutex::new(0))` — три рівні обгортки
2. **Клонування**: `Arc::clone()` для кожного потоку
3. **Доступ**: `counter_clone.lock().unwrap()` — захоплюємо mutex
4. **Мутація**: `*num += 1` — безпечно
5. **Звільнення**: автоматичне при виході зі scope
6. **Результат**: завжди коректний!

### Візуальне представлення

```
        ┌─────────────────────────────────────────────────┐
        │                     HEAP                        │
        │  ┌─────────────────────────────────────────┐   │
        │  │  Arc внутрішня структура                │   │
        │  │  ┌─────────────────────────────────┐    │   │
        │  │  │ strong_count: 11 (атомарний)    │    │   │
        │  │  └─────────────────────────────────┘    │   │
        │  │  ┌─────────────────────────────────┐    │   │
        │  │  │ Mutex внутрішня структура       │    │   │
        │  │  │ ┌─────────────────────────────┐ │    │   │
        │  │  │ │ locked: true/false          │ │    │   │
        │  │  │ └─────────────────────────────┘ │    │   │
        │  │  │ ┌─────────────────────────────┐ │    │   │
        │  │  │ │ data: 10                    │ │    │   │
        │  │  │ └─────────────────────────────┘ │    │   │
        │  │  └─────────────────────────────────┘    │   │
        │  └─────────────────────────────────────────┘   │
        └─────────────────────────────────────────────────┘
                    ▲   ▲   ▲   ▲   ▲   ...
                    │   │   │   │   │
              ┌─────┴───┴───┴───┴───┴─────┐
              │  10 потоків + main потік  │
              │  (кожен має свій Arc)     │
              └───────────────────────────┘
```

### Мінімізація критичної секції

**Критична секція** — код між lock та unlock. Поки один потік у критичній секції, **інші заблоковані**.

**Постановка задачі:** Показати правильну та неправильну критичну секцію.

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn expensive_computation(x: i32) -> i32 {
    // Імітація важкого обчислення
    std::thread::sleep(std::time::Duration::from_millis(100));
    x * 2
}

fn main() {
    let data = Arc::new(Mutex::new(0));
    
    // ❌ ПОГАНО: тривала критична секція
    // let mut guard = data.lock().unwrap();
    // let result = expensive_computation(*guard);  // 100мс під lock!
    // *guard = result;
    
    // ✅ ДОБРЕ: мінімальна критична секція
    
    // Крок 1: Швидко прочитали, звільнили lock
    let value = {
        let guard = data.lock().unwrap();
        *guard  // Копіюємо значення
    };  // guard знищено — mutex вільний!
    
    // Крок 2: Обчислення БЕЗ блокування інших
    let result = expensive_computation(value);
    
    // Крок 3: Швидко записали результат
    {
        let mut guard = data.lock().unwrap();
        *guard = result;
    }  // Знову вільний
    
    println!("Результат: {}", *data.lock().unwrap());
}
```

**Принцип:** захоплюйте lock → робіть мінімум → звільняйте lock.

---

## 34.5 RwLock: оптимізація для сценаріїв читання

### Проблема надмірного блокування

Mutex блокує **будь-який** доступ — і читання, і запис. Але читання **не конфліктує** з читанням! Якщо 10 потоків хочуть прочитати карту, вони могли б робити це одночасно.

З Mutex вони стоятимуть у черзі без потреби.

### RwLock — розумніший підхід

**RwLock** (Read-Write Lock) розрізняє типи доступу:
- **Читання** — багато потоків одночасно
- **Запис** — тільки один, і тільки коли немає читачів

Правила:
- Багато читачів **АБО** один писар
- Писар чекає, поки всі читачі звільнять lock
- Нові читачі чекають, поки писар завершить

**Постановка задачі:** Показати паралельне читання через RwLock.

```rust
use std::sync::RwLock;

fn main() {
    let lock = RwLock::new(vec![1, 2, 3, 4, 5]);
    
    // Багато читачів ОДНОЧАСНО — ефективно!
    {
        let r1 = lock.read().unwrap();  // Перший читач
        let r2 = lock.read().unwrap();  // Другий — теж OK!
        let r3 = lock.read().unwrap();  // Третій — теж OK!
        
        // Всі три активні одночасно
        println!("r1[0] = {}", r1[0]);
        println!("r2 sum = {}", r2.iter().sum::<i32>());
        println!("r3 len = {}", r3.len());
    }  // Всі read guards звільнені
    
    // Запис — ексклюзивний
    {
        let mut w = lock.write().unwrap();
        w.push(6);
        // Поки w існує — ніхто не може ні читати, ні писати
    }
    
    println!("Після запису: {:?}", *lock.read().unwrap());
}
```

### Коли обирати RwLock

| Патерн | Рекомендація | Чому |
|--------|--------------|------|
| Переважно запис | Mutex | RwLock не дає переваг |
| Переважно читання | RwLock | Читачі працюють паралельно |
| Рівномірно | Mutex | Простіший, менше overhead |
| Короткі операції | Mutex | Overhead RwLock не виправдовується |
| Довге читання | RwLock | Читачі не блокують один одного |

---

## 34.6 Deadlock: смертельні обійми

### Що таке deadlock

**Deadlock** — ситуація, коли потоки заблоковані **назавжди**, кожен чекаючи на ресурс, що утримується іншим.

Аналогія: двоє людей у вузькому коридорі. Кожен хоче пройти, жоден не поступається. Вони стоять вічно.

### Як виникає deadlock

**Постановка задачі:** Продемонструвати класичний deadlock.

```rust
use std::sync::{Arc, Mutex};
use std::thread;
use std::time::Duration;

fn main() {
    let resource_a = Arc::new(Mutex::new("Ресурс A"));
    let resource_b = Arc::new(Mutex::new("Ресурс B"));
    
    let a1 = Arc::clone(&resource_a);
    let b1 = Arc::clone(&resource_b);
    
    // Потік 1: захоплює A, потім B
    let handle1 = thread::spawn(move || {
        let _guard_a = a1.lock().unwrap();
        println!("Потік 1: захопив A");
        
        thread::sleep(Duration::from_millis(10));  // Даємо час потоку 2
        
        println!("Потік 1: чекаю B...");
        let _guard_b = b1.lock().unwrap();  // ← Чекатиме ВІЧНО!
        println!("Потік 1: захопив B");
    });
    
    let a2 = Arc::clone(&resource_a);
    let b2 = Arc::clone(&resource_b);
    
    // Потік 2: захоплює B, потім A — ЗВОРОТНІЙ порядок!
    let handle2 = thread::spawn(move || {
        let _guard_b = b2.lock().unwrap();
        println!("Потік 2: захопив B");
        
        thread::sleep(Duration::from_millis(10));
        
        println!("Потік 2: чекаю A...");
        let _guard_a = a2.lock().unwrap();  // ← Чекатиме ВІЧНО!
        println!("Потік 2: захопив A");
    });
    
    // Ця програма ЗАВИСНЕ назавжди!
    handle1.join().unwrap();
    handle2.join().unwrap();
}
```

**Що відбувається:**
```
Потік 1: захопив A
Потік 2: захопив B
Потік 1: чекаю B...    ← B утримує Потік 2
Потік 2: чекаю A...    ← A утримує Потік 1
(вічне очікування)
```

### Стратегії уникнення

**Стратегія 1: Фіксований порядок**

Завжди захоплювати mutex у **тому самому порядку**:

```rust
// Правило: ЗАВЖДИ спочатку A, потім B
let _guard_a = resource_a.lock().unwrap();
let _guard_b = resource_b.lock().unwrap();
```

Якщо всі потоки дотримуються — циклічне очікування неможливе.

**Стратегія 2: Один mutex**

Об'єднати пов'язані дані:

```rust
let resources = Arc::new(Mutex::new((resource_a, resource_b)));

let mut guard = resources.lock().unwrap();
guard.0 = "new A";
guard.1 = "new B";
```

**Стратегія 3: try_lock**

Не блокувати, а перевіряти:

```rust
loop {
    if let Ok(guard_a) = resource_a.try_lock() {
        if let Ok(guard_b) = resource_b.try_lock() {
            // Маємо обидва — працюємо
            break;
        }
        // Не вдалось — звільняємо A, пробуємо знову
    }
    thread::sleep(Duration::from_millis(1));
}
```

### Важливо: Rust НЕ захищає від deadlock

Rust гарантує відсутність **data races** (гонок даних), але **не deadlocks**.

Data race — помилка пам'яті, виявляється через типи. Deadlock — логічна помилка, залежить від порядку виконання, який неможливо передбачити при компіляції.

---

## 34.7 Практичний приклад: спільна карта світу

**Постановка задачі:** Кілька агентів ділять карту світу. Читання часте, оновлення рідкісне — ідеально для `Arc<RwLock<T>>`.

```rust
use std::sync::{Arc, RwLock};
use std::collections::HashMap;
use std::thread;

type Position = (i32, i32);

#[derive(Clone, Debug, PartialEq)]
enum CellType {
    Unknown,
    Empty,
    Obstacle,
    Target,
}

struct WorldMap {
    cells: HashMap<Position, CellType>,
}

impl WorldMap {
    fn new() -> Self {
        Self { cells: HashMap::new() }
    }
    
    fn get(&self, pos: Position) -> CellType {
        self.cells.get(&pos).cloned().unwrap_or(CellType::Unknown)
    }
    
    fn set(&mut self, pos: Position, cell: CellType) {
        self.cells.insert(pos, cell);
    }
    
    fn explored_count(&self) -> usize {
        self.cells.len()
    }
}

type SharedMap = Arc<RwLock<WorldMap>>;

fn main() {
    let map: SharedMap = Arc::new(RwLock::new(WorldMap::new()));
    
    let mut handles = vec![];
    
    // 3 агенти досліджують різні напрямки
    for agent_id in 0..3 {
        let map_clone = Arc::clone(&map);
        
        handles.push(thread::spawn(move || {
            for step in 0..5 {
                let pos = (agent_id * 10 + step, agent_id * 10 + step);
                
                // Перевіряємо (read lock — паралельно з іншими читачами)
                let is_unknown = {
                    let guard = map_clone.read().unwrap();
                    guard.get(pos) == CellType::Unknown
                };
                
                if is_unknown {
                    // Оновлюємо (write lock — ексклюзивно)
                    let mut guard = map_clone.write().unwrap();
                    guard.set(pos, CellType::Empty);
                    println!("[Agent {}] Досліджено {:?}", agent_id, pos);
                }
            }
        }));
    }
    
    for handle in handles {
        handle.join().unwrap();
    }
    
    let final_map = map.read().unwrap();
    println!("\nВсього досліджено клітин: {}", final_map.explored_count());
}
```

---

## 34.8 Лабораторна робота

**Мета:** Безпечно організувати спільний стан між потоками.

### Частина 1: Паралельний лічильник (3 бали)

10 потоків × 1000 інкрементів = результат 10000.

### Частина 2: Спільна статистика місії (4 бали)

Структура `MissionStats` оновлюється кількома агентами.

### Частина 3: Кеш з RwLock (3 бали)

Читання часте, оновлення рідкісне.

---

## Підсумок

| Інструмент | Призначення |
|------------|-------------|
| `Arc<T>` | Спільне володіння між потоками |
| `Mutex<T>` | Ексклюзивний доступ |
| `RwLock<T>` | Багато читачів АБО один писар |
| `Arc<Mutex<T>>` | Спільний мутабельний стан |

**Ключові правила:**

- ✅ Rc → однопотоковий, Arc → багатопотоковий
- ✅ Мінімізуйте критичні секції
- ✅ Фіксований порядок захоплення mutex
- ⚠️ Rust захищає від data races, але **не від deadlocks**

---

## Зв'язок з наступним розділом

Arc + Mutex — підхід "спільної пам'яті". Але є альтернатива: **"не спілкуйтесь через спільну пам'ять — діліться пам'яттю через спілкування"**.

Замість одночасної зміни даних потоки можуть **надсилати повідомлення**. Цей підхід — **message passing**.

У **Розділі 35: Channels** ви дізнаєтесь:
- Філософію передачі повідомлень
- Як працюють mpsc канали в Rust
- Коли обирати канали замість mutex
